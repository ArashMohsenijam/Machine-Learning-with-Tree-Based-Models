{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indian Liver Patient Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data from UCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age  Gender  Total_Bilirubin  Direct_Bilirubin  Alkaline_Phosphotase  \\\n",
      "310   51    Male              0.8               0.2                   175   \n",
      "311   54  Female             23.2              12.6                   574   \n",
      "312   27    Male              1.3               0.6                   106   \n",
      "313   30  Female              0.8               0.2                   158   \n",
      "314   26    Male              2.0               0.9                   195   \n",
      "315   22    Male              0.9               0.3                   179   \n",
      "316   44    Male              0.9               0.2                   182   \n",
      "317   35    Male              0.7               0.2                   198   \n",
      "318   38    Male              3.7               2.2                   216   \n",
      "319   14    Male              0.9               0.3                   310   \n",
      "\n",
      "     Alamine_Aminotransferase  Aspartate_Aminotransferase  Total_Protiens  \\\n",
      "310                        48                          22             8.1   \n",
      "311                        43                          47             7.2   \n",
      "312                        25                          54             8.5   \n",
      "313                        25                          22             7.9   \n",
      "314                        24                          65             7.8   \n",
      "315                        18                          21             6.7   \n",
      "316                        29                          82             7.1   \n",
      "317                        42                          30             6.8   \n",
      "318                       179                         232             7.8   \n",
      "319                        21                          16             8.1   \n",
      "\n",
      "     Albumin  Albumin_and_Globulin_Ratio  Dataset  \n",
      "310      4.6                         1.3        1  \n",
      "311      3.5                         0.9        1  \n",
      "312      4.8                         NaN        2  \n",
      "313      4.5                         1.3        2  \n",
      "314      4.3                         1.2        1  \n",
      "315      3.7                         1.2        2  \n",
      "316      3.7                         1.0        2  \n",
      "317      3.4                         1.0        1  \n",
      "318      4.5                         1.3        1  \n",
      "319      4.2                         1.0        2  \n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('indian_liver_patient.csv')\n",
    "print(df.iloc[310:320, :])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate the DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 583 entries, 0 to 582\n",
      "Data columns (total 11 columns):\n",
      "Age                           583 non-null int64\n",
      "Gender                        583 non-null object\n",
      "Total_Bilirubin               583 non-null float64\n",
      "Direct_Bilirubin              583 non-null float64\n",
      "Alkaline_Phosphotase          583 non-null int64\n",
      "Alamine_Aminotransferase      583 non-null int64\n",
      "Aspartate_Aminotransferase    583 non-null int64\n",
      "Total_Protiens                583 non-null float64\n",
      "Albumin                       583 non-null float64\n",
      "Albumin_and_Globulin_Ratio    579 non-null float64\n",
      "Dataset                       583 non-null int64\n",
      "dtypes: float64(5), int64(5), object(1)\n",
      "memory usage: 50.2+ KB\n",
      "Age                           0\n",
      "Gender                        0\n",
      "Total_Bilirubin               0\n",
      "Direct_Bilirubin              0\n",
      "Alkaline_Phosphotase          0\n",
      "Alamine_Aminotransferase      0\n",
      "Aspartate_Aminotransferase    0\n",
      "Total_Protiens                0\n",
      "Albumin                       0\n",
      "Albumin_and_Globulin_Ratio    4\n",
      "Dataset                       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort the dataset from ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaNs\n",
    "Data = df.dropna()\n",
    "\n",
    "# Convert categorical variable into dummy/indicator variables. \n",
    "Data=pd.get_dummies(Data,drop_first=True)\n",
    "\n",
    "# Convert Dataset column values from two to zero (boolean)\n",
    "Data['Dataset'].replace({2,1},inplace=True)\n",
    "\n",
    "# Rename columns for ease of use\n",
    "Data.rename(columns={'Gender_Male':'Is_male','Dataset':'Liver_disease'},inplace=True)\n",
    "\n",
    "# Define ML input (X) and output (y)\n",
    "X=Data.drop('Liver_disease',axis=1)\n",
    "y=Data.Liver_disease\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Train and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import proper Sklearn packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Import BaggingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Import Accuracy Score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Import AdaBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Import roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy of bc: 0.68\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a DecisionTreeClassifier 'dt' with a maximum depth of 6\n",
    "dt = DecisionTreeClassifier(max_depth=6, random_state=10)\n",
    "\n",
    "# Fit dt to the training set\n",
    "dt = dt.fit(X_train,y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = dt.predict(X_test)\n",
    "acc_test = accuracy_score(y_test, y_pred)\n",
    "print('Test set accuracy of bc: {:.2f}'.format(acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the bagging classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Instantiate bc\n",
    "bc = BaggingClassifier(base_estimator=dt, n_estimators=50, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Bagging performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy of bc: 0.74\n"
     ]
    }
   ],
   "source": [
    "# Fit bc to the training set\n",
    "bc.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = bc.predict(X_test)\n",
    "\n",
    "# Evaluate acc_test\n",
    "acc_test = accuracy_score(y_test, y_pred)\n",
    "print('Test set accuracy of bc: {:.2f}'.format(acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the AdaBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(max_depth=6, random_state=1)\n",
    "\n",
    "# Instantiate ada\n",
    "ada = AdaBoostClassifier(base_estimator=dt, n_estimators=180, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the AdaBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit ada to the training set\n",
    "ada.fit(X_train,y_train)\n",
    "\n",
    "# Compute the probabilities of obtaining the positive class\n",
    "y_pred_proba = ada.predict_proba(X_test)[:,1]\n",
    "y_pred_ada=ada.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the AdaBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.81\n",
      "Test set accuracy of ada: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Evaluate test-set roc_auc_score\n",
    "ada_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "acc_test_ada = accuracy_score(y_test, y_pred_ada)\n",
    "# Print roc_auc_score\n",
    "print('ROC AUC score: {:.2f}'.format(ada_roc_auc))\n",
    "print('Test set accuracy of ada: {:.2f}'.format(acc_test_ada))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'presort': False, 'random_state': 10, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier (random_state=10)\n",
    "\n",
    "print(dt.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the tree's hyperparameter grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define params_dt\n",
    "params_dt = {'max_depth':[2,3,4],'min_samples_leaf':[0.12,0.14,0.16,0.18]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for the optimal tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort=False, random_state=10,\n",
       "                                              splitter='best'),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'max_depth': [2, 3, 4],\n",
       "                         'min_samples_leaf': [0.12, 0.14, 0.16, 0.18]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate grid_dt\n",
    "grid_dt = GridSearchCV(estimator=dt,\n",
    "                       param_grid=params_dt,\n",
    "                       scoring='roc_auc',\n",
    "                       cv=5,\n",
    "                       n_jobs=-1)\n",
    "grid_dt.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the optimal tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set ROC AUC score: 0.680\n"
     ]
    }
   ],
   "source": [
    "# Extract the best estimator\n",
    "best_model = grid_dt.best_estimator_\n",
    "\n",
    "# Predict the test set probabilities of the positive class\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Compute test_roc_auc\n",
    "test_roc_auc = roc_auc_score(y_test,y_pred_proba)\n",
    "\n",
    "# Print test_roc_auc\n",
    "print('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
